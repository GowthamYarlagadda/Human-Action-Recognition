{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-12T08:17:51.640235Z","iopub.execute_input":"2022-08-12T08:17:51.640600Z","iopub.status.idle":"2022-08-12T08:17:51.751417Z","shell.execute_reply.started":"2022-08-12T08:17:51.640569Z","shell.execute_reply":"2022-08-12T08:17:51.750516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tensorflow.keras.utils import to_categorical\nimport itertools\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport pickle\nimport cv2\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.753234Z","iopub.execute_input":"2022-08-12T08:17:51.753575Z","iopub.status.idle":"2022-08-12T08:17:51.761251Z","shell.execute_reply.started":"2022-08-12T08:17:51.753541Z","shell.execute_reply":"2022-08-12T08:17:51.760422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_data = pd.read_csv(\"../input/ucf50labels/UCF50_Classes.txt\", sep=' ', header=None)\nlabel_data.columns=['labels']\n\nlabel_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.763054Z","iopub.execute_input":"2022-08-12T08:17:51.763706Z","iopub.status.idle":"2022-08-12T08:17:51.786368Z","shell.execute_reply.started":"2022-08-12T08:17:51.763672Z","shell.execute_reply":"2022-08-12T08:17:51.785440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(label_data)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.789189Z","iopub.execute_input":"2022-08-12T08:17:51.789808Z","iopub.status.idle":"2022-08-12T08:17:51.796736Z","shell.execute_reply.started":"2022-08-12T08:17:51.789775Z","shell.execute_reply":"2022-08-12T08:17:51.795243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path=[]\nfor label in label_data.labels.values:\n#     path.append('../input/ucf101/UCF101/UCF-101/'+label+\"/\")\n    path.append('../input/ucf50-action-recognition-dataset/UCF50/'+label+\"/\")\npath[0]","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.798543Z","iopub.execute_input":"2022-08-12T08:17:51.799256Z","iopub.status.idle":"2022-08-12T08:17:51.808077Z","shell.execute_reply.started":"2022-08-12T08:17:51.799223Z","shell.execute_reply":"2022-08-12T08:17:51.806974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.810779Z","iopub.execute_input":"2022-08-12T08:17:51.811227Z","iopub.status.idle":"2022-08-12T08:17:51.816203Z","shell.execute_reply.started":"2022-08-12T08:17:51.811194Z","shell.execute_reply":"2022-08-12T08:17:51.815042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_extraction(video_path):\n    width=60\n    height=60\n    sequence_length=5\n    frames_list=[]\n    #Read the Video\n    video_reader = cv2.VideoCapture(video_path)\n    #get the frame count\n    frame_count=int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n    #Calculate the interval after which frames will be added to the list\n    skip_interval = max(int(frame_count/sequence_length), 1)\n    #iterate through video frames\n    for counter in range(sequence_length):\n        #Set the current frame postion of the video\n        video_reader.set(cv2.CAP_PROP_POS_FRAMES, counter * skip_interval)\n        #Read the current frame \n        ret, frame = video_reader.read()\n        if not ret:\n            break;\n        #Resize the image\n        frame=cv2.resize(frame, (height, width))\n        frame = frame/255\n        #Append to the frame\n        frames_list.append(frame)\n    video_reader.release()\n    #Return the Frames List\n    return frames_list","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.817720Z","iopub.execute_input":"2022-08-12T08:17:51.818168Z","iopub.status.idle":"2022-08-12T08:17:51.828563Z","shell.execute_reply.started":"2022-08-12T08:17:51.818135Z","shell.execute_reply":"2022-08-12T08:17:51.827658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef load_video(datasets):\n    global image\n    label_index=0\n    labels=[]\n    images=[]\n    #Iterate through each foler corresponding to category\n    for folder in datasets:\n        for file in tqdm(os.listdir(folder)):\n            #Get the path name for each video\n            video_path = os.path.join(folder, file)\n            #Extract the frames of the current video\n            frames_list = feature_extraction(video_path)\n            images.append(frames_list)\n            labels.append(label_index)\n        label_index+=1\n    return np.array(images, dtype='float16'), np.array(labels, dtype='int8')","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.830315Z","iopub.execute_input":"2022-08-12T08:17:51.830694Z","iopub.status.idle":"2022-08-12T08:17:51.838845Z","shell.execute_reply.started":"2022-08-12T08:17:51.830656Z","shell.execute_reply":"2022-08-12T08:17:51.837775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = load_video(path[:])","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:17:51.840426Z","iopub.execute_input":"2022-08-12T08:17:51.841136Z","iopub.status.idle":"2022-08-12T08:21:51.811405Z","shell.execute_reply.started":"2022-08-12T08:17:51.841092Z","shell.execute_reply":"2022-08-12T08:21:51.810265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images.shape, pd.Series(labels).shape ","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:51.815953Z","iopub.execute_input":"2022-08-12T08:21:51.816259Z","iopub.status.idle":"2022-08-12T08:21:51.825158Z","shell.execute_reply.started":"2022-08-12T08:21:51.816232Z","shell.execute_reply":"2022-08-12T08:21:51.823974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_on1=open('labels.pkl','wb')\npickle.dump(labels,p_on1)\np_on1.close()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:51.827132Z","iopub.execute_input":"2022-08-12T08:21:51.828047Z","iopub.status.idle":"2022-08-12T08:21:51.834244Z","shell.execute_reply.started":"2022-08-12T08:21:51.828011Z","shell.execute_reply":"2022-08-12T08:21:51.832830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test=train_test_split(images, labels, test_size=0.06, random_state=10)\nx_train.shape, x_test.shape, np.array(y_train).shape, np.array(y_test).shape","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:51.835812Z","iopub.execute_input":"2022-08-12T08:21:51.836293Z","iopub.status.idle":"2022-08-12T08:21:52.011033Z","shell.execute_reply.started":"2022-08-12T08:21:51.836257Z","shell.execute_reply":"2022-08-12T08:21:52.009879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_on=open('x_train.pkl','wb')\npickle.dump(x_train,p_on)\np_on.close()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:52.012848Z","iopub.execute_input":"2022-08-12T08:21:52.013265Z","iopub.status.idle":"2022-08-12T08:21:53.288390Z","shell.execute_reply.started":"2022-08-12T08:21:52.013229Z","shell.execute_reply":"2022-08-12T08:21:53.286891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_on=open('x_test.pkl','wb')\npickle.dump(x_test,p_on)\np_on.close()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:53.294897Z","iopub.execute_input":"2022-08-12T08:21:53.298090Z","iopub.status.idle":"2022-08-12T08:21:53.391662Z","shell.execute_reply.started":"2022-08-12T08:21:53.298043Z","shell.execute_reply":"2022-08-12T08:21:53.390439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_on=open('y_train.pkl','wb')\npickle.dump(y_train,p_on)\np_on.close()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:53.398008Z","iopub.execute_input":"2022-08-12T08:21:53.401132Z","iopub.status.idle":"2022-08-12T08:21:53.410174Z","shell.execute_reply.started":"2022-08-12T08:21:53.401080Z","shell.execute_reply":"2022-08-12T08:21:53.408992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_on=open('y_test.pkl','wb')\npickle.dump(y_test,p_on)\np_on.close()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:53.423907Z","iopub.execute_input":"2022-08-12T08:21:53.426274Z","iopub.status.idle":"2022-08-12T08:21:53.434108Z","shell.execute_reply.started":"2022-08-12T08:21:53.426237Z","shell.execute_reply":"2022-08-12T08:21:53.432460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2, input_shape=(x_train.shape[1],x_train.shape[2], x_train.shape[3], 3)))\nmodel.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\nmodel.add(TimeDistributed(Dropout(0.2)))\n\nmodel.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2))\nmodel.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\nmodel.add(TimeDistributed(Dropout(0.2)))\n\nmodel.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2))\nmodel.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\nmodel.add(TimeDistributed(Dropout(0.2)))\n\nmodel.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2))\nmodel.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\nmodel.add(TimeDistributed(Dropout(0.2)))\n\nmodel.add(Flatten())\n          \nmodel.add(Dense(50, activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:53.440134Z","iopub.execute_input":"2022-08-12T08:21:53.442589Z","iopub.status.idle":"2022-08-12T08:21:53.981664Z","shell.execute_reply.started":"2022-08-12T08:21:53.442555Z","shell.execute_reply":"2022-08-12T08:21:53.980486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:53.983253Z","iopub.execute_input":"2022-08-12T08:21:53.983591Z","iopub.status.idle":"2022-08-12T08:21:54.478020Z","shell.execute_reply.started":"2022-08-12T08:21:53.983557Z","shell.execute_reply":"2022-08-12T08:21:54.476926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:54.479829Z","iopub.execute_input":"2022-08-12T08:21:54.480865Z","iopub.status.idle":"2022-08-12T08:21:54.494785Z","shell.execute_reply.started":"2022-08-12T08:21:54.480824Z","shell.execute_reply":"2022-08-12T08:21:54.493832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:21:54.496907Z","iopub.execute_input":"2022-08-12T08:21:54.497669Z","iopub.status.idle":"2022-08-12T08:21:54.504454Z","shell.execute_reply.started":"2022-08-12T08:21:54.497633Z","shell.execute_reply":"2022-08-12T08:21:54.503383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\nhistory = model.fit(x_train, to_categorical(y_train), batch_size=32, epochs=60, validation_data=(x_test, to_categorical(y_test)), callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:10:17.023724Z","iopub.execute_input":"2022-08-12T10:10:17.024416Z","iopub.status.idle":"2022-08-12T10:17:04.822879Z","shell.execute_reply.started":"2022-08-12T10:10:17.024375Z","shell.execute_reply":"2022-08-12T10:17:04.821956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(13,5))\nplt.title(\"Accuracy vs Epochs\")\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Test Accuracy')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:19:25.943753Z","iopub.execute_input":"2022-08-12T10:19:25.944667Z","iopub.status.idle":"2022-08-12T10:19:26.243516Z","shell.execute_reply.started":"2022-08-12T10:19:25.944629Z","shell.execute_reply":"2022-08-12T10:19:26.242555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\npredicted_classes=[]\nfor i in range(len(y_test)):\n    predicted_classes.append(np.argmax(y_pred[i]))","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:18:37.589324Z","iopub.execute_input":"2022-08-12T10:18:37.590055Z","iopub.status.idle":"2022-08-12T10:18:43.037845Z","shell.execute_reply.started":"2022-08-12T10:18:37.590017Z","shell.execute_reply":"2022-08-12T10:18:43.036830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, predicted_classes)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:18:43.508517Z","iopub.execute_input":"2022-08-12T10:18:43.509279Z","iopub.status.idle":"2022-08-12T10:18:43.517624Z","shell.execute_reply.started":"2022-08-12T10:18:43.509242Z","shell.execute_reply":"2022-08-12T10:18:43.516600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,25))\nplt.title(\"Confusion matrix\")\ncm=confusion_matrix(y_test, predicted_classes)\nplt.imshow(cm)\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment=\"center\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:19:33.165178Z","iopub.execute_input":"2022-08-12T10:19:33.165792Z","iopub.status.idle":"2022-08-12T10:19:39.669698Z","shell.execute_reply.started":"2022-08-12T10:19:33.165758Z","shell.execute_reply":"2022-08-12T10:19:39.668813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('UCF50_Model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:19:53.302468Z","iopub.execute_input":"2022-08-12T10:19:53.302834Z","iopub.status.idle":"2022-08-12T10:19:53.350854Z","shell.execute_reply.started":"2022-08-12T10:19:53.302804Z","shell.execute_reply":"2022-08-12T10:19:53.349884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmod=load_model('./UCF50_Model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:49:53.421238Z","iopub.execute_input":"2022-08-12T08:49:53.421506Z","iopub.status.idle":"2022-08-12T08:49:53.894728Z","shell.execute_reply.started":"2022-08-12T08:49:53.421481Z","shell.execute_reply":"2022-08-12T08:49:53.893728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_videos = np.random.randint(0,len(x_test),size=(10))\npredicted  = mod.predict(x_test[random_videos],batch_size = 10)\npredicted  = np.argmax(predicted,axis=1)\nprint(predicted)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:49:53.899716Z","iopub.execute_input":"2022-08-12T08:49:53.900022Z","iopub.status.idle":"2022-08-12T08:49:54.626093Z","shell.execute_reply.started":"2022-08-12T08:49:53.899995Z","shell.execute_reply":"2022-08-12T08:49:54.624997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_videos = np.random.randint(0,len(x_test),size=(10))\npredicted  = mod.predict(x_test[random_videos],batch_size = 10)\npredicted  = np.argmax(predicted,axis=1)\nfig = plt.figure(figsize=(20,10))\n\nfor i,rand_indx in enumerate(random_videos):\n    \n    ax = plt.subplot(2,5,i+1)\n    video = x_test[rand_indx]\n    frame = video[np.random.randint(0,5)]\n    frame=frame.astype('float32')\n    s=label_data['labels']\n    ax.set_title(s[predicted[i]])\n    \n    \n    plt.imshow(frame)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:20:16.367060Z","iopub.execute_input":"2022-08-12T10:20:16.367472Z","iopub.status.idle":"2022-08-12T10:20:17.345823Z","shell.execute_reply.started":"2022-08-12T10:20:16.367444Z","shell.execute_reply":"2022-08-12T10:20:17.344869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cap = cv.VideoCapture(1)\n# cap.set(cv.CAP_PROP_FPS, 10)\n# cap.set(3, 800)\n# cap.set(4, 800)\n\n# if not cap.isOpened():\n#   cap = cv.VideoCapture(0)\n# if not cap.isOpened():\n#   raise IOError(\"cannot open webcam\")\n\n\n\n\n# while cv.waitKey(1) < 0:\n#     hasFrame, frame = cap.read()\n#     if not hasFrame:\n#         cv.waitKey()\n#         break\n\n#     frameWidth = frame.shape[1]\n#     frameHeight = frame.shape[0]\n#     inp = cv.dnn.blobFromImage(frame, 0.2, (inWidth, inHeight),\n#                               (0, 0, 0), swapRB=False, crop=False)\n#     net.setInput(inp)\n#     out = net.forward()\n\n#     assert(len(BODY_PARTS) <= out.shape[1])\n\n#     points = []\n#     for i in range(len(BODY_PARTS)):\n#         # Slice heatmap of corresponding body's part.\n#         heatMap = out[0, i, :, :]\n\n#         # Originally, we try to find all the local maximums. To simplify a sample\n#         # we just find a global one. However only a single pose at the same time\n#         # could be detected this way.\n#         _, conf, _, point = cv.minMaxLoc(heatMap)\n#         x = (frameWidth * point[0]) / out.shape[3]\n#         y = (frameHeight * point[1]) / out.shape[2]\n\n#         # Add a point if it's confidence is higher than threshold.\n#         points.append((int(x), int(y)) if conf > thr else None)\n\n#     for pair in POSE_PAIRS:\n#         partFrom = pair[0]\n#         partTo = pair[1]\n#         assert(partFrom in BODY_PARTS)\n#         assert(partTo in BODY_PARTS)\n\n#         idFrom = BODY_PARTS[partFrom]\n#         idTo = BODY_PARTS[partTo]\n\n#         if points[idFrom] and points[idTo]:\n#             cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n#             cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n#             cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n\n#     t, _ = net.getPerfProfile()\n#     freq = cv.getTickFrequency() / 1000\n#     cv.putText(frame, '%.2fms' % (t / freq), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n\n#     cv.imshow('OpenPose using OpenCV', frame)\n#     if cv.waitKey(1) & 0xFF == ord('q'):\n#         break\n# cap.release()\n# cv.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T08:49:55.607913Z","iopub.execute_input":"2022-08-12T08:49:55.608488Z","iopub.status.idle":"2022-08-12T08:49:55.616941Z","shell.execute_reply.started":"2022-08-12T08:49:55.608451Z","shell.execute_reply":"2022-08-12T08:49:55.615451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}